---
sidebar_label: 'Module 4: Vision-Language-Action (VLA)'
sidebar_position: 4
---

# Module 4: Vision-Language-Action (VLA)

## Overview
Convergence of LLMs and Robotics. Voice commands with OpenAI Whisper. Cognitive planning from natural language to ROS actions.

## Topics Covered
- Voice-to-Action with Whisper
- LLM planning ("Clean the room" â†’ ROS 2 tasks)
- Multimodal perception (vision + language)
- Natural interaction pipelines

For detailed specification, see the [full specification](../specs/6-vla-integration/spec.md).